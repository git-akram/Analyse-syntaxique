\documentclass{article}
\usepackage[francais]{babel}
\def\printlandscape{\special{landscape}} % Works with dvips.
\usepackage{geometry}
\geometry{ hmargin=3cm, vmargin=2.5cm } % set margin
\usepackage{graphicx}% include image
%\usepackage{pstricks,pst-node,pst-tree}
%\usepackage{amssymb}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{fancybox} % for shadow and Bitemize
\usepackage{alltt}
\usepackage{graphicx}
%\usepackage{epsfig}
%\usepackage{fullpage}
%\usepackage{fancyhdr}
%\usepackage{moreverb}
%\usepackage{xspace}
\usepackage[colorlinks,hyperindex,bookmarks,linkcolor=blue,citecolor=blue,urlcolor=blue]{hyperref}
\usepackage{placeins}
\usepackage{wrapfig}
\usepackage{epsf}
\setcounter{secnumdepth}{4}
\setcounter{tocdepth}{3}
\makeatletter
\newcounter {subsubsubsection}[subsubsection]
\renewcommand\thesubsubsubsection{\thesubsubsection .\@alph\c@subsubsubsection}
\newcommand\subsubsubsection{\@startsection{subsubsubsection}{4}{\z@}%
                                     {-3.25ex\@plus -1ex \@minus -.2ex}%
                                     {1.5ex \@plus .2ex}%
                                     {\normalfont\normalsize\bfseries}}
\newcommand*\l@subsubsubsection{\@dottedtocline{3}{10.0em}{4.1em}}
\newcommand*{\subsubsubsectionmark}[1]{}
\makeatother


\title{Analyse Syntaxique}
\author{Mohammed Akram Rhafrane - Ismail Senhaji - Nathanaël Bertrand - Mehdi Boutchiche\\}
\date{\today} 
\begin{document}




\begin{figure}[t]
	\centering
		\includegraphics[width=0.60\textwidth]{logo-ups.jpg}
	\label{fig:logo-ups}
\end{figure}

\maketitle

\newpage
\tableofcontents

\newpage
\begin{abstract}
Le processus de compilation passe par une série d’étapes afin de de générer un programme cible à partir d’un programme source, il passe par une série d’étapes dont l’une qui nous intéresse qui est l’analyse syntaxique. Son principe est de recevoir une série d’unités lexicales formé à l’aide de l’analyse lexicale puis généré un arbre de syntaxe abstraite à base d’une grammaire qui définit le langage traduit. L’analyse syntaxique se base sur deux principes fondamentaux, l’analyse LL qui suit un cheminement de dérivation de gauche à droite et l’analyse LR qui suit le cheminement contraire, c’est à dire que les symboles les plus à droite sont dérivés en premier.
\end{abstract}

%-----------------------------------------------------------
\section{Introduction}
\label{hints}
Un compilateur est un programme qui lit en entrée un programme écrit dans un premier langage dit langage source, et le traduit en un programme équivalent écrit dans un autre langage dit langage cible.
Au cours de ce processus de traduction, le compilateur tentera également de repérer et de signaler les erreurs qui peuvent être commises par le programmeur.

\begin{figure}[h]
	\centering
		\includegraphics[width=0.70\textwidth]{compilateur.png}
	\caption{Compilateur}
	\label{fig:compilateur}
\end{figure}\FloatBarrier

Afin de générer un programme source a partir du programme source, le compilateur passe par plusieurs étapes en commençant par l'analyse lexicale jusqu'à la génération du code. Voici un schéma montrant le processus de compilation en détails:

\begin{figure}[h]
	\centering
		\includegraphics[width=0.90\textwidth]{compilation.png}
	\caption{Processus de compilation}
	\label{fig:compilation}
\end{figure}\FloatBarrier

Cette étude de la théorie de compilation s'intéresse de plus près à la phase de l'analyse syntaxique qui permet de générer des arbres de syntaxe abstraite à partir d'une suite d'unité lexicales.
Une deuxième étude sera faite afin de comparer entre l'analyse LL \ref{sec:LL} et l'analyse LR \ref{sec:LR} qui sont deux approches principales de l'analyse syntaxique.
A la fin, un partie sera consacré à la démonstration de l’outil Xtext qui permet de définir différents aspects du langage traduit.  

\section{Fondamenteux}
\label{hints}
\subsection{Langages et grammaires}
\subsubsection{Défintion}
Un langage formel est un ensemble de mots constitués de symboles qui appartiennent à son alphabet.
Un langage formel est décrit par une grammaire.
De manière générale, une grammaire est définie par un quadruplet:

    N : l’ensemble des non-terminaux utilisés pour décrire les règles de productions

    X : l’ensemble des terminaux, c’est à dire les symboles ou encore l’alphabet

    P : l’ensemble des règles de production

    S : l’axiome, c’est un élément de N
\newline

Ainsi, la notation: G(L) = <N, X, P, S> décrit la grammaire G associée au langage L.
Les grammaires sont analysées par des automates. Il existe plusieurs types d’analyses de grammaires qui font appels à plusieurs types d’automates.
Dans le monde de la compilation l’analyseur syntaxique fait référence à l’algorithme qui met en oeuvre l’automate d’analyse d’une grammaire.
Dans cet écrit, nous nous attarderons sur deux types d’analyseurs: les analyseurs de type LL et ceux de type L(AL)R.

\subsubsection{Grammaires ambiguë}
On dit qu’une grammaire est ambiguë  lorsqu’on peut trouver deux arbres de dérivation différents pour le même mot.
Les grammaires ambiguë pose un problème lors de la compilation, c’est pour ça qu’il est préférable de les transformer en grammaire non ambiguë si c’est possible.\newline
\textit{Exemple : }\newline\newline
Prenons la grammaire suivante G=( \textit{\{E\} , \{a,+,}x\textit{\} , R , E} ) \newline
Avec \textit{R} donné par : \textit{E := E} x \textit{E | E + E | a}


\begin{figure}[h]
	\centering
		\includegraphics[width=0.90\textwidth]{grammaireAmbigue.png}
	\label{fig:grammaireAmbigue}
\end{figure}\FloatBarrier

Donc nous remarquons qu'on peut construire deux arbres de dérivation à partir de la chaîne de caractères 
\textit{"a + a} x \textit{a"} 

\subsection{Analyse lexicale}
l’analyse lexicale consiste à découper une chaîne de caractère en unités lexicales ou lexèmes à la demande de l’analyseur lexicale.
Il est définit par un ensembles d’expressions relationnelles qui exigent certaines séquences de caractère pour former les lexèmes.
\textit{Exemple :}

\begin{figure}[h]
	\centering
		\includegraphics[width=0.80\textwidth]{AnalyseLexicale.png}
	\caption{Analyse lexicale}
	\label{fig:AnalyseLexicale}
\end{figure}\FloatBarrier


\subsubsection{Unités lexicales}
Une unité lexicale ou un lexème est une chaîne de caractère qui correspond à un symbole. à l’aide du processus de segmentation, on peut extraire à partir d’un flux de caractères entrant une suite d’unités lexicales, ensuite c’est l’analyseur lexicale qui traitent ces lexème et les rangent dans des catégories d’entités lexicales.

\subsubsection{Analyseur Lexicale}

On appelle analyseur lexical \cite{refAnalyseurLexicale}, lexeur, ou encore scanneur, tout programme effectuant une analyse lexicale. Il s'agit le plus souvent d'une unique fonction qui sera appelée par l'analyseur syntaxique \ref{sec:analyseurSyntaxique} ou par une autre fonction.

Le scanneur contient toutes les informations sur les séquences de caractères qui peuvent être contenues dans les entités lexicales qu'il génère. Par exemple, une entité lexicale de type « INTEGER » peut contenir n'importe quelle séquence de caractères numériques (chiffres).

Son rôle consiste à :
\begin{itemize}
			\item Eliminer les « bruits » du texte source : commentaires, espaces, …
			\item Reconnaître les opérateurs et les mots-clés : ==, if, …
			\item Reconnaître les chaînes de caractères, les identificateurs et les constantes numériques
\end{itemize}
Il produit en sortie une entité lexicale qui sera utilisée par l'analyseur syntaxique.

Un analyseur lexical peut être écrit :
\begin{itemize}
			\item « à la main » : il faut construire l'automate fini non déterministe à partir d'une expression rationnelle E, puis l'exécuter pour déterminer si une chaîne d'entrée appartient au langage reconnu par E
			\item Par une table décrivant l'automate et un programme exploitant cette table
			\item Par un générateur d'analyseurs : Flex, ANTLR, Lex, etc.
\end{itemize}    

\subsubsection{Segmentation}
La segmentation est le fait de séparer les différentes sections d’une chaînes de caractères, par exemple pour une phrase l’ordinateur la considère comme une chaîne de caractère et non pas une suite de mot, le rôle de la segmentation est donc de faire une séparation entre ces mots selon le caractère de séparation dans ce cas le caractère espace.

\subsection{Analyse syntaxique}\label{sec:analyseurSyntaxique}
Le rôle de l’analyse syntaxique \cite{refAnalyseSyntaxique} est de savoir si une phrase appartient à la syntaxe d’un langage.
A partir du flot de lexèmes construits par l’analyse lexicale dans un premier temps, l’analyse syntaxique permet de générer un arbre de syntaxe abstraite.
Cet arbre est construit à base d’un ensembles de règles définissant une grammaire formelle sur laquelle est basé le langage en question.
l’analyse syntaxique permet plus particulièrement de détecter les erreurs de syntaxe en continuant tout de même l’analyse pour éviter les cycles de compilation/correction pour les développeurs.\newline
\textit{Exemple :}\newline
Reprenant l'exemple de d'analyse lexicale \ref{fig:AnalyseLexicale}. L'analyse lexicale a construit une suites d'unités lexicales a partir d'une chaîne de caractères en entrée.\newline
Maintenant le rôle de l'analyse syntaxique est de reprendre ce résultat et essayer de construire un arbre de syntaxe suivant la grammaire qui définit le langage afin de s'assurer que la chaîne de caractères appartient au langage.

\begin{figure}[h]
	\centering
		\includegraphics[width=0.80\textwidth]{AnalyseSyntaxique.png}
	\caption{Analyse syntaxique}
	\label{fig:AnalyseSyntaxique}
\end{figure}\FloatBarrier
\textit{Exemple :}\cite{refModernCompiler}
\label{ex:ModernCompiler}
\newline\newline
S => S ; S\newline
S => id := E\newline
S => print(L)\newline
E => id\newline
E => num\newline
E => E + E\newline
E => (S , E)\newline
L => E\newline
L => L , E\newline

Considérons la phrase id := num; id := id + (id := num + num, id)\newline
Une dérivation à gauche se représenterait de la forme suivante :\newline\newline
\underline{S}\newline
S ; \underline{S}\newline
\underline{S} ; id := E\newline
id := \underline{E} ; id := E\newline
id := num ; id := \underline{E}\newline
id := num ; id := E + \underline{E}\newline
id := num ; id := \underline{E} + (S , E )\newline
id := num ; id := id + (\underline{S} , E )\newline
id := num ; id := id + (id := \underline{E} , E )\newline
id := num ; id := id + (id := E + E , \underline{E} )\newline
id := num ; id := id + (id := \underline{E} + E , id )\newline
id := num ; id := id + (id := num + \underline{E} , id )\newline
id := num ; id := id + (id := num + num , id )\newline

\subsubsection{Analyseur syntaxique}

L'analyseur syntaxique est une programme qui reçoit une suite d'unités lexicales de la part de l'analyseur lexicale et doit vérifier que cette suite est engendrée par la grammaire du langage décrit.

Voici un schema montrant les intéractions entre l'analyseur lexicale et l'analyseur syntaxique:

\begin{figure}[h]
	\centering
		\includegraphics[width=0.70\textwidth]{interactionLexSynt.png}
	\caption{Interaction entre l'analyseur lexicale et l'analyseur syntaxique}
	\label{fig:interactionLexSynt}
\end{figure}\FloatBarrier

En ce qui concerne le fonctionnement interne, l'analyseur syntaxique est une machine à états. 

Elle consiste en :
\begin{itemize}
    \item Un tampon d'entrée ;
    \item Une pile dans laquelle est stockée la liste des états où elle est passée ;
    \item Une table des branchements qui indique vers quel état elle doit aller ;
    \item Une table des actions qui donne la règle de grammaire à appliquer en fonction de l'état courant et du terminal courant du flot d'entrée.
\end{itemize}

un analyseur syntaxique doit retracer le cheminement d’application des règles qui ont menées à l’axiome. Pour ça, il existe deux types d’analyse:

\subsubsection{Analyse descendante}\label{sec:analyseDes}
Le principe de l’analyse descendante est de partir de l’axiome en suivant les règles de production afin de retrouver le texte analysé. Ce type d’analyse procède en découpant le texte petit à petit jusqu'à retrouver les unité lexicale. L’analyse LL est un exemple d’analyse descendante.\newline
\textit{Exemple :}\newline
On a :\newline
S => aSbT | cT | d\newline
T => aT | bS | c \newline
et la chaîne suivante en entrée W=acbbadbc\newline
On part avec l'arbre contenant le seul sommet S.
La lecture de la première lettre du mot (a) nous permet d'avancer la construction de l'arbre avec :

\begin{figure}[h]
	\centering
		\includegraphics[width=0.70\textwidth]{AnalyseDescendante1.png}
	\label{fig:AnalyseDescendante1}
\end{figure}\FloatBarrier

Puis la deuxième lettre nous amène à :

\begin{figure}[h]
	\centering
		\includegraphics[width=0.70\textwidth]{AnalyseDescendante2.png}
	\label{fig:AnalyseDescendante2}
\end{figure}\FloatBarrier

et ainsi de suite jusqu'a la fin du mot.

\begin{figure}[h]
	\centering
		\includegraphics[width=0.70\textwidth]{AnalyseDescendante3.png}
	\label{fig:AnalyseDescendante3}
\end{figure}\FloatBarrier

Donc le mot appartient au langage. Sur cet exemple c'est simple car chaque règle commence par un terminal différent ce qui facilite le choix de la règle à appliquer. Mais c'est pas toujours le cas, dans la plus part des cas on se trouve devant le choix entre plusieur règles par exemple si on considère :\newline
S => aAb\newline
A => cd | c \newline
et on veut lire le mot W=acb\newline
On se retrouve avec

\begin{figure}[h]
	\centering
		\includegraphics[width=0.70\textwidth]{AnalyseDescendante4.png}
	\label{fig:AnalyseDescendante4}
\end{figure}\FloatBarrier

En lisant le caractère "c", on ne sait pas si il faut choisir la règle A => cd ou bien A => c.
Pour le savoir il faut lire le caractère suivant "b", ou alors, il faut se donner la possibilité de de faire des retours en arrière :
On essaye la première règle, on aboutit à un echec, alors on retourneen arrière pour essayer la deuxième règle.

\subsubsection{Analyse ascendante}
L’analyse ascendante d’une autre part, procède contrairement à l’analyse descendante en retrouvant le cheminement à partir du texte analysé. Ce type d’analyse essaye de regrouper les unité lexicale entre elles pour retrouver l’axiome. L’analyse LR est un exemple d’analyse ascendante.
Reprenons l'exemple dernier \ref{sec:analyseDes} :
Cette fois en utilisant une analyse ascendante, on va partir de la chaîne de caractères pour retrouver l'axiome S.
La chaîne analysé est la même du dernier exemple \newline W=accbbadbc\newline\newline\newline
\begin{tabular}{|l|l|}
\hline
\textbf{a}ccbbadbc & Aucune règle à appliquer\\
\hline
a\textbf{c}cbbadbc & Aucune règle à appliquer\\
\hline
ac\textbf{c}bbadbc & T => c\\
\hline
ac\textbf{T}bbadbc & S => cT\\
\hline
a\textbf{S}bbadbc & Aucune règle à appliquer\\
\hline
aS\textbf{b}badbc & Aucune règle à appliquer\\
\hline
aSb\textbf{b}adbc & Aucune règle à appliquer\\
\hline
aSbb\textbf{a}dbc & Aucune règle à appliquer\\
\hline
aSbba\textbf{d}bc & S => d\\
\hline
aSbba\textbf{S}bc & Aucune règle à appliquer\\
\hline
aSbbaS\textbf{b}c & Aucune règle à appliquer\\
\hline
aSbbaSb\textbf{c} & T => c\\
\hline
aSbbaSb\textbf{T} & S => aSbT\\
\hline
aSbb\textbf{S} & T => bS\\
\hline
aSb\textbf{T} & S => aSbT\\
\hline
S & Axiome retrouvé\\
\hline
\end{tabular}
\newline\newline\newline
Alors le mot "accbbadbc" est bien dans le langage.

\subsubsection{Analyse deterministe}

Un analyseur syntaxique, en tant que système de réécriture, est déterministe si une seule règle de réécriture est applicable dans chaque configuration de l'analyseur. Par extension, il ne peut alors y avoir qu'une seule séquence de règles permettant d'analyser le texte dans sa totalité, et donc celui-ci ne peut être syntaxiquement ambigu. Toutefois, il peut être fait usage de techniques telles que la pré-vision (en anglais lookahead) ou le backtracking pour déterminer quelle règle il faut appliquer à un point donné de l'analyse.

Les méthodes d'analyse déterministes sont principalement employées pour l'analyse des langages de programmation. Par exemple, les analyses LR, LL, ou LALR (employée par Yacc) sont toutes déterministes. On ne peut cependant pas construire un analyseur déterministe pour n'importe quelle grammaire non contextuelle. Dans ce cas, et si l'on souhaite n'avoir qu'une seule analyse en sortie, on est contraint de lui adjoindre des mécanismes supplémentaires, comme des règles de désambiguïsation ou des modèles probabilistes permettant de choisir la « meilleure » analyse.

Une méthode d’analyse descendante et déterministe est dite prédictive \cite{refAnalyseSyntaxique}.

\subsubsection{Analyse non deterministe}

La taille et la complexité des langues naturelles, sans oublier leur inévitable ambiguïté, rend leur analyse déterministe totalement impossible. Une analyse non déterministe s'apparente à une résolution dans un système contraint, et s'exprime assez aisément en Prolog.

L'emploi de méthodes tabulaires, mémorisant les calculs intermédiaires, sera plus efficace qu'un simple backtracking. L'analyse CYK est un exemple d'analyse tabulée, à laquelle on préférera des méthodes plus sophistiquées

    d'analyse à chartes comme l'analyse Earley
    ou d'analyse LR généralisée (GLR).

Ces deux dernières méthodes d'analyse sont aussi appréciées pour l'analyse de langages de programmation dont la syntaxe est ambiguë, comme par exemple C++.

\subsubsection{Récupération des erreurs}

En analyse syntaxique des langages de programmation, il faut être capable de continuer l'analyse même lorsque le code source contient des erreurs, pour éviter des cycles de compilation/correction fastidieux pour le développeur. De même, en analyse syntaxique des langues naturelles, il faut pouvoir analyser des énoncés même s'ils ne sont pas couverts par la grammaire, inévitablement incomplète. La récupération sur erreur, ou rattrapage d'erreur (anglais error recovery), doit être suffisamment efficace pour détecter les problèmes, et "faire avec", moyennant une correction du source ou la faculté de produire des analyses (légèrement) déviantes par rapport à la grammaire. On peut citer quelques approches qui vont dans ce sens.

\subsubsubsection{Mode panique}

le mode panique \cite{refModePanique} est un cas particulier de mode dégradé, c’est-à-dire une méthode de récupération sur erreur.
Par exemple, lorsqu'une erreur survient lors d'une analyse syntaxique, l'analyseur supprime un à un chaque prochain symbole jusqu'à ce qu'il atteigne un symbole permettant de se resynchroniser.

\subsubsubsection{Production erreurs}

L'utilisation de productions erreurs \cite{refProductionErreurs} est une méthode de récupération sur erreur. Elle consiste à ajouter à la grammaire d'un langage des productions contenant la notion d'erreur. Cette technique est notamment utilisée par Yacc.

\subsubsubsection{Correction locale}

La correction locale \cite{refCorrectionLocale} est une technique de récupération sur erreur. Lorsqu'un analyseur constate une erreur lors de la lecture d'un symbole, il remplace le symbole lu par un autre qui lui semble plus juste.

\subsection{LL - Left to right Leftmost derivation}\label{sec:LL}

L'analyse LL est une analyse descendante pour un sous-ensemble de grammaire non contextuelle. Son principe est  d'analyser l'entrée de gauche à droite (Left to right) et de construire une dérivation à gauche (Leftmost derivation). Les grammaires analysables de cette façon sont nommées grammaires LL.
Une analyse LL est appelée analyse LL(k) lorsqu'elle utilise k lexèmes d'avance.\newline
\textit{Exemple :}

Reprenons l'exemple \ref{ex:ModernCompiler} \newline
Une dérivation à gauche de la phrase id := num ; id := id + (id := num + num, id) se présenterait de la forme suivante :\newline\newline
\underline{S}\newline
\underline{S} ; S\newline
id := \underline{E} ; S\newline
id := num ; \underline{S}\newline
id := num ; id := \underline{E}\newline
id := num ; id := \underline{E} + E\newline
id := num ; id := id + \underline{E}\newline
id := num ; id := id + (\underline{S}, E)\newline
id := num ; id := id + (id := \underline{E} , E)\newline
id := num ; id := id + (id := \underline{E} + E, E)\newline
id := num ; id := id + (id := num + \underline{E}, E)\newline
id := num ; id := id + (id := num + num, \underline{E})\newline
id := num ; id := id + (id := num + num, id)\newline

Le principe de l'analsye LL est simple, le symbole nom terminal le plsu à gauche est toujours celui à être développé en premier et ainsi de suite jusqu'a ce que la phrase soit reconnu. 

\subsection{LR - Left to right Rightmost derivation}\label{sec:LR}

un analyseur LR (pour Left to right, Rightmost derivation) \cite{LR} est un analyseur pour les grammaires non contextuelles qui lit l'entrée de gauche à droite et produit une dérivation droite. On parle aussi d'analyseur LR(k) où k représente le nombre de symboles « anticipés » et non consommés qui sont utilisés pour prendre des décisions d'analyse syntaxique. D'habitude, k vaut 1 et est souvent omis. Une grammaire non contextuelle est appelée LR(k) s'il existe un analyseur syntaxique LR(k) pour elle.
On dit qu'un analyseur syntaxique LR réalise une analyse ascendante car il essaye de déduire les productions du niveau du haut de la grammaire en les construisant à partir des feuilles.
De nombreux langages de programmation sont décrits par des grammaires LR(1), ou du même genre, et, pour cette raison, les analyseurs syntaxiques LR sont souvent utilisés par les compilateurs pour faire l'analyse syntaxique de code source.
Typiquement, quand on se réfère à un analyseur syntaxique LR, on parle d'un analyseur syntaxique capable de reconnaître un langage particulier spécifié par une grammaire non contextuelle. Cependant, dans l'usage courant, on utilise le terme pour parler d'un programme pilote qui peut être appelé avec une certaine table et qui produit un large éventail d'analyseurs syntaxiques LR différents.

L'analyse syntaxique LR a plusieurs avantages :
\begin{itemize}
    \item De nombreux langages de programmation peuvent être analysés en utilisant une variante d'analyseur syntaxique LR. Une exception notable est C++ ;
    \item Les analyseurs syntaxiques LR peuvent être implémentés très efficacement ;
    \item De tous les analyseurs syntaxiques qui parcourent leur entrée de gauche à droite, les parseurs LR détectent les erreurs de syntaxe (c'est-à-dire quand les entrées ne sont pas conformes à la grammaire) le plus tôt possible.
\end{itemize}
\textit{Exemple :}
\newline\newline
Reprenons l'exemple \ref{ex:ModernCompiler} mais cette fois avec une dérivation à droite de la phrase \newline 
id := num ; id := id + (id := num + num, id) va suivre ce cheminement :\newline\newline
\underline{S}\newline
S ; \underline{S}\newline
S ; id := \underline{E}\newline
S ; id := E + \underline{E}\newline
S ; id := E + (S, \underline{E})\newline
S ; id := E + (\underline{S}, id)\newline
S ; id := E + (id := \underline{E}, id)\newline
S ; id := E + (id := E + \underline{E}, id)\newline
S ; id := E + (id := \underline{E} + num, id)\newline
S ; id := \underline{E} + (id := num + num, id)\newline
\underline{S} ; id := id + (id := num + num, id)\newline
id := \underline{E} ; id := id + (id := num + num, id)\newline
id := num ; id := id + (id := num + num, id)\newline

Le principe de l'analyse syntaxique LR impose au contraire de l'analyse LL que le symbole non terminal le plus à droite qui soit developpé de manière répétitive jusqu'a ce que la phrase soit accepté si elle appartient au langage.

Les analyseurs syntaxiques LR sont difficiles à produire à la main ; ils sont généralement construits par des générateurs d'analyse syntaxique ou des compilateurs de compilateurs. Suivant la manière dont la table d'analyse syntaxique est générée, ces analyseurs syntaxiques sont appelés : 
\begin{itemize}
\item Analyseurs syntaxiques LR simples SLR (Simple LR parser).
\item Analyseurs syntaxiques LR avec anticipation LALR (Look-Ahead LR parser).
\item Analyseurs syntaxiques canoniques.
\end{itemize} 

Ces types d'analyseurs syntaxiques peuvent traiter des ensembles de grammaires de plus en plus grands ; les analyseurs syntaxiques LALR peuvent traiter plus de grammaires que les SLR. tandis que les analyseurs syntaxiques canoniques fonctionnent sur davantage de grammaires que les analyseurs syntaxiques LALR. 

Le plus connu est Yacc \ref{sec:yacc} qui produit des analyseurs syntaxiques LALR.

\section{Comparaison entre les outils}
\label{hints}

\subsection{YACC - Yet Another Compiler-Compiler}
\label{sec:yacc}
YACC est un programme qui permet de générer un analyseur syntaxique à partir d’une spécification. La spécification est l’ensemble des règles de grammaire associées au langage à analyser.
L’analyseur ainsi généré est de type LALR(1).

\subsubsection{Specification}
La spécification est l’ensemble des données qui permettront à YACC de générer l’analyseur. Elle décrit le langage qui sera reconnu sous forme de règles de grammaires. De cette façon l’analyseur a les connaissances pour définir si un flux donné en entrée est syntaxiquement correcte par rapport à sa spécification.
Cependant, un analyseur syntaxique est souvent utilisé dans le contexte de traduction de langage. La spécification permet cette fonctionnalité puisqu’il est possible de spécifier des actions associées aux règles de grammaire.

\begin{figure}[h]
	\centering
		\includegraphics[width=0.70\textwidth]{yaccDiagramme.png}
	\caption{Description de YACC}
	\label{fig:yaccDiagramme}
\end{figure}\FloatBarrier

La spécification suit la structure suivante :

Bloc des déclarations

%%

Règles de grammaire

%%

Programme

Les sections “Bloc des déclarations” et “Programme” sont facultatives.

Une règle de grammaire est notée sous la forme:

A : B \{ /* action pour cette regle */ \};

\subsubsection{ Exemples }

\subsubsubsection{ Mini calculatrice }
Ci-dessous un exemple de spécification Yacc qui génère une calculatrice très minimaliste. Exemple inspiré de http://www.gaudry.be/langages-yacc.html puis modifié pour être fonctionnel.
L'analyseur syntaxique ainsi généré peut-être utilisé en tant qu'interpreteur de commandes permettant de faire des opérations simples telles que: \newline
2+5\newline
(1+2)\newline
1*2\newline
2*(2+1)\newline
À noter que pour plus de simplicité, les nombres à plusieurs chiffres ne sont pas pris en charge.
La grammaire reconnu par cet analyseur syntaxique est la suivante:
G(L) = <N,X,P,S>
Avec :
\begin{verbatim}
N : { ligne, commande, expr, terme, facteur }
X : { [0-9], \n, +, *, (, ) }
P : {
    ligne -> 		
        commande \n ligne
        | \n
    commande :	
        expr
    expr :		
        expr + terme
        | terme
    terme : 		
        terme * facteur
        | facteur
    facteur : 		
         ( expr )
        | [0-9]
}
S : ligne
\end{verbatim}


Ici, on utilise Yacc sans Lex afin de comprendre le fonctionnement. Cependant, il faut définir à la main la fonction yylex(). Celle-ci renvoie un entier qui indique le type de token qui a été reconnu en entrée. Si on avait utilisé Lex comme scanner, cette fonction aurait déjà été définie.

\begin{verbatim}

%{
    #include <ctype.h>
    #include <stdio.h>
    #include <stdlib.h>
%}

%token CHIFFRE

%%
ligne : commande '\n' ligne
    | '\n' { printf("Fin du programme\n"); exit(0); }
    ;

commande: expr { printf("Resultat: %d\n", $1); };


expr : expr '+' terme { $$ = $1 + $3; }
    | terme
    ;
   
terme : terme '*' facteur { $$ = $1 * $3; }
    | facteur
    ;
   
facteur : '(' expr ')' { $$ = $2; }
    | CHIFFRE
    ;

%%
int main(){
    yyparse();   
}

int yyerror(char *s){
    printf("%s \n", s);
}


int yylex(){
    int c;
    c = getchar();
    if(isdigit(c)){
        yylval = c-'0';
        return CHIFFRE;
    }
    return c;
}

\end{verbatim}

Pour faire fonctionner cet exemple, il faudra entrer les lignes de commande suivantes:

> bison exemple1.y

> gcc exemple1.tab.c -o exemple1

> ./exemple1

Dans cet exemple, on a défini 5 règles. À quelques unes de ces règles on a associé des actions afin d’effectuer les calculs sur les chiffres lus.

Ces actions sont des instructions C dans lesquelles on a accès à des variables spéciables.
Ainsi les variables \$n font référence à la valeur du n-ième élément de droite et \$\$ fait référence à l’élément de gauche.


\subsubsubsection{ Langage de manipulation de catégories }

Uu autre exemple un peu plus avancé qui permet de parser un langage qui gère des catégories. L'exemple est certe scolaire mais montre bien quelques problèmes et solutions qui peuvent survenir lors de l'écriture d'une spécification.

\begin{verbatim}
%{
    #include <ctype.h>
    #include <stdio.h>
    #include <stdlib.h>
    #include <string.h>
    
    typedef struct {
        char nom[256];
        int ratio;
    } Cat_Struct;
    
    int previousTestResult;
    int previousRatioResult;
    char currentCategorie[256] = "";
    Cat_Struct listCategorie[100];
    int listCategorieCount = 0;
    
    int categorieIndexOf(char *s){
        int i;
        for(i=0;i<listCategorieCount;i++){
            if(strcmp(listCategorie[i].nom, s) == 0){
                return i;
            }    
        }
        return -1;
    }
    
    int categorieExists(char *s){
        return categorieIndexOf(s) >= 0;    
    }
    
    int categorieAdd(char *s){
        if(categorieExists(s)) return 0;
        
        strcpy(listCategorie[listCategorieCount].nom, s);
        listCategorie[listCategorieCount].ratio = 0;
        listCategorieCount++;
        return 1;
    }
    
    int categorieSetRatio(char *s, int ratio){
        if(!categorieExists(s)) return 0;
        int i = categorieIndexOf(s);
        
        listCategorie[i].ratio = ratio;
        return 1;
    }
    
    char* categorieToString(char *s){
        if(!categorieExists(s)) return "";
        int i = categorieIndexOf(s);
        
        char* toString = (char*)malloc(sizeof(char)*300);
        sprintf(toString, "[nom: %s, ratio: %d]", listCategorie[i].nom, listCategorie[i].ratio);
        return toString;
    }
    
    void categoriePrintAll(){
        if(listCategorieCount == 0){
            printf("Aucune categorie en memoire\n");
            return;
        } else {
            printf("%d categories enregistrees\n", listCategorieCount);
        }


        int i;
        for(i=0;i<listCategorieCount;i++){
            if(strcmp(listCategorie[i].nom, currentCategorie) == 0) printf("> ");
            printf("Categorie : %s\n", categorieToString(listCategorie[i].nom));    
        }
    }
%}
 
%token IDENTIFIANT
%token RATIOVALUE

%union 
{
    int num;
    char *str;
}
 
%%

Model : Ligne Model
    | Ligne
    ;

Ligne : 
    Categorie '\n' 
    | Rule '\n'
    | Commande '\n'
    ;

Categorie : 'c''a''t''e''g''o''r''i''e' IDENTIFIANT 
    { 
        strcpy(currentCategorie, yylval.str);
        if(!categorieExists(currentCategorie)){
            categorieAdd(currentCategorie);
            printf("[Nouvelle categorie]\n");    
        }
        printf("> Categorie : %s\n", categorieToString(currentCategorie));
    };
    ;

Rule : RuleExpression
    | RuleExpression 'e''l''s''e' RuleExpression
    | RuleExpression 'e''l''s''e' RatioExpression
    ;
    
RuleExpression : 'i''f' TestExpression 't''h''e''n' RatioExpression 
    { 
        if(previousTestResult){
            categorieSetRatio(currentCategorie, previousRatioResult);
        }
    }
    ;
    
TestExpression : 'c''a''t''e''g''o''r''i''e' '=' IDENTIFIANT     
    {
        if(strcmp(yylval.str, currentCategorie) == 0){
            // Match
            previousTestResult = 1;
        } else {
            previousTestResult = 0;
        }
    }
    ;
    
RatioExpression : 'r''a''t''i''o' '=' RATIOVALUE    
    {
        previousRatioResult = yylval.num;
    }
    ;
    
Commande : 
    'c''u''r''r''e''n''t' { printf("Categorie courante: %s\n", currentCategorie); }
    || 'p''r''i''n''t' { categoriePrintAll(); }
    ;
//*/
%%
int main(){
    yyparse();    
}

int yyerror(char *s){
    printf("%s \n", s);
}


int yylex(){
    int c;
    int isDigit = -1;
    int digitValue = 0;
    char stringValue[256] = "";
    int tmpSize;
    while(c = getchar()){
        if(c == ' ') continue;
        
        if(!(c >= 'a' && c <= 'z') && c != '"' && !isdigit(c) && c != '.') break;
        if(isDigit == -1){
            if(isdigit(c)){
                isDigit = 1;
                digitValue = c - '0';
            }
            else if(c == '"'){
                isDigit = 0;
            }
            else return c;
        }
        else if(isDigit == 1){
            if(isdigit(c)){
                digitValue = digitValue * 10 + (c - '0');
            } else if(c == '.'){
                yylval.num = digitValue;
                return RATIOVALUE;
            }
        }
        else if(isDigit == 0){ 
            if(c=='"'){
                yylval.str = stringValue;
                return IDENTIFIANT;
            } else {
                tmpSize = strlen(stringValue);
                stringValue[tmpSize] = c;
                stringValue[tmpSize+1] = '\0';
            }
        }
    }
    return c;
}
\end{verbatim}



\subsection{ANTLR - ANother Tool for Language Recognition}
Pour obtenir une certaines flexibilité et une meilleures gestion d’erreurs, les programmeurs préfèrent écrire leurs parseurs de descente récursive à la main, nous allons donc vous présentez dans ce chapitre un outil, qui combine flexibilité, gestion d’erreurs  et présente tout les avantages d’un générateur de parseur, cet outil est ANTLR.
\subsubsection{Défintions}
ANTLR \cite{refANTLR} est un générateur de parseur public, il propose plusieurs fonctionnalités qui rendent son utilisation simple, il propose  des prédicats qui permettent aux programmeurs de diriger et de contrôler le parseur grâce à des expressions syntaxiques et sémantique.
ANTLR permet aussi d’intégrer des  descriptions lexicales et syntaxiques et peut générer automatiquement l’arbre syntaxique.
\subsubsection{Fonctionnement}
Comme ce qui a été dit précédemment dans l’introduction, les prédicats permettent de diriger le parseur, ainsi ANTLR peut générer des parseurs pour plusieurs et différents langages.
Les prédicats sémantiques indiquent la validité sémantique d’une production, les prédicats syntaxiques sont quant à eux des fragments de grammaires qui décrivent un contexte syntaxique qui doit être satisfait avant de reconnaître une production associée.
\subsubsection{Fonctionnalités}
Fort d’une stratégie puissante autant que parseur, ANTLR a plusieurs fonctionnalités qui rendent sont utilisation plus agréable que d’autres LR/LALR et LL générateurs de parseurs.
\begin{itemize}
\item ANTLR  intègre la spécification entre une analyse lexicale et syntaxique.
			\item ANTLR facilite la construction de l’arbre syntaxique.
			\item ANTLR génère des parseurs de descente récursives en C et C++.
			\item ANTLR   facilite la gestion d’erreurs.
			\item ...
\end{itemize}

\subsubsection{Eléments de langages}
Le tableau illustre quelques éléments de langage spécifique à ANTLR qui le distinguent des autres générateurs de parseurs.
\newline

\begin{tabular}{|l|l|l|}
\hline
Elément de langages & Description & Exemple \\
\hline
Token & Commence par majuscule & ID \\
\hline
<<...>> & Définie une action sémantique & << printf ("\%S",a );>> \\
\hline	
(...) & Régle & ( "int" | ID  | storage\_class ) \\
\hline
(...)* & Closure & ID("," ID)* \\
\hline
(...)+ & Positive Closure & slist : ( stat | SEMICOLON ) + ; \\
\hline
\{...\} & Optionnel & \{ELSE stat\} \\
\hline
<<...>>? & Prédicat sémantique & type : << is\_Type(str)>> ? ID ; \\
\hline
(...)? & Prédicat syntaxique & ((list EQ))? list EQ list | list ) \\
\hline
\end{tabular}
\subsubsection{Langage et description}
\subsubsubsection{Description de langage et ANTLR}
Une description ANTLR est un collection de règles et d'actions précédé par une en-tête dans laquelle l'utilisateur définis les types des attributs par exemple.

Une règles ANTLR est entre autre une liste d'alternatives séparées par"|":


règle : \textit{alternative \textsl{1}} | \textit{alternative \textsl{2}} |... |\textit{alternative \textsl{n}};


Chaque alternative est composée d'une liste d'éléments.Les règles définissent aussi des arguments et retournent des valeurs, dans l'exemple suivant, il y a \textsl{n} arguments et \textsl{m} valeurs retournées:


\textit{règles}[\textit{args \textsl{1}},...,\textit{args \textsl{n}}] > [\textit{returnVal \textsl{1}},...,\textit{returnVal \textsl{m}}]


Notons aussi qu'une description ANTLR est diffèrentes de celle des autres parseurs générateurs car les expressions régulières sont spécifiées (\#token ID) ou directement référencées (\#segment). Ces spécifications lexicale ou grammaticale se trouvent dans un fichier, ainsi plus besoin de mantenir deux spécifications. ANTLR assigne automatiquement le type des unités lexicales et génère l'analyseur syntaxique.

Autre point important, ANTLR optimise le choix du nombre de lookahead en utilisant le moins possible. En effet, ANTLR génère une décision qui utilise un symbole qui distingue entre la première alternative et les autres. Ainsi, le prgrammeur utilise la puissance d'un parseur LL(k) avec k > 1 sans se soucier de l'efficacité ou non du parseur. Par exemple, si une règle requiert trois symboles pour différencier entre deux alternatives, ANTLR s'en occupe et génère un symbole pour faire la différence.
ANTLR permet aussi à l'utilisateur de définir des actions et de les appeler là où il veut dans une production ANTLR, ces actions sont utilisées pour améliorer les tests sémantiques, générer une représenation intermédiaire ou directement générer la traduction.

\subsubsubsection{Prédicats}

ANTLR supporte l'utilisation de prédicats sémantique et syntaxique qui permet à l'utilisateur d'indiquer la validté sémantique et syntaxique d'une production, permettant ainsi à ANTLR de gérer naturellement des situations d'analyse difficile.

\subsubsection{Quelques fonctionnalités utile aux programmeurs}

\subsubsubsection{Intégration de l'analyse syntaxique et lexicale}

Une description ANTLR contient à la fois une spécification pour l'analyse des unités lexicales et la spécification du parseur lui-même, ce qui élimine le besoin d'avoir deux fichiers différents pour chaque spécification, en effet ANTLR extrait automatiquement une description de l'analyseur lexicale à partir de la description intégrée de ANTLR.
ANTLR permet ainsi l'utilisation de plusieurs analyseurs lexicaux dans la même description ANTLR, cette pratique permet alors l'analyse de plusieurs langages.
\subsubsubsection{Gestion d'erreurs}
ANTLR propose deux mécanismes pour la gestion des erreurs.Dans le premier mécanisme, ANTLR génère un message d'erreur en utilisant une simple heuristique qui est suffisante pour plusieurs applications. par contre, quand une gestion d'erreurs plus complexe est requise, ANTLR fourni un second mécanisme appelé Parseur de gestion d'exceptions qui offre une construction de rapport plus flexible dans un framework convenant.
Le premier mécanisme génère automatiquement des rapports d'erreurs, désigne là où l'erreur a été détecté et qu'est ce qui était attendu.
Le premier mécanisme, qui génère automatiquement des rapports d'erreurs, désigne là l'erreur à été détecté et qu'est ce qui était attendu.
Le second mécanisme quant à lui, fournis un framework pour y mettre les rapports d'erreurs sémantiques et syntaxiques, notons que le premier mécanisme ne reconnait pas les erreurs sémantiques.

\subsubsubsection{Construction de l'arbre syntaxique}

Le plus souvent, les parseurs construisent une forme intermédiaire qui sera utilisé plus tard dans des phases de compilation par exemple. En utilisant quelques annotations, ANTLR peut automatiquement construire un arbre syntaxique, évitant ainsi à l'utilisateur d'appeler la construction d'un arbre à chaque fois.
Pour créer un arbre, l'utilisateur des annotations grammaticales qui indiquent le noeud père, les feuilles et aussi qui doit être exclu de l'abre. Les unités lexicales précédés de "!" par exemple, son à exclure de l'arbre.Toutes les autres unités lexicales sont considérées comme des feuilles.
Voici un petit exemple de la constrcuction d'un arbre syntaxique : 
\begin{verbatim}
	if 3 + 4 * 5 then return 4;
\end{verbatim}

L'arbre correspondant :

\begin{figure}[h]
	\centering
		\includegraphics[width=0.80\textwidth]{ast.jpg}
	\label{fig:ast_process}
\end{figure}\FloatBarrier

\subsubsection{Exemple simple avec ANTLR}
Dans cette partie, nous allons vous montrez comment utiliser ANTLR dans un IDE tel que Eclipse.
\subsubsubsection{ANTLR}
\begin{itemize}
	\item Télécharger et installer ANTLR à partir du site officiel : www.antlr.org
	\item Ouvrir votre IDE, nous utilisons Eclipse.
	\item Créer un projet Java et y ajouter le support ANTLR ainsi que la nature ANTLR  comme suit :
	
	\begin{figure}[h]
	\centering
		\includegraphics[width=1.10\textwidth,height=13cm]{AntlrIdeSupport.JPG}
	\label{fig:AntlrIdeSupport.JPG}
	\end{figure}\FloatBarrier
		
		\begin{figure}[h]
	\centering
		\includegraphics[width=1.10\textwidth,height=13cm]{AntlrNature.JPG}
	\label{fig:AntlrNature.JPG}
	\end{figure}\FloatBarrier

\item Ensuite créer un nouveau fichier ANTLR, nous choisissons Combined Grammar pour écrire à la fois et dans un même fichier les régles de l'analyseur syntaxique (PARSER) et les régles lexicales (LEXER), notez que dans options nous pouvons chosir quel langage utiliser, pour notre exemple nous allons travailler en java pour l'utiliser sour l'IDE eclipse, on peux changer et écrire en C\#,C,Phyton...

		\begin{figure}[h]
	\centering
		\includegraphics[width=1.10\textwidth,height=13cm]{AntlrFile.JPG}
	\label{fig:AntlrFile.JPG}
	\end{figure}\FloatBarrier

\end{itemize}
\subsubsubsection{Exécuter ANTLR sur un exemple simple}
Création d'un exemple simple en C et en Java  :
\begin{itemize}
	\item Tout d'abord l'exemple écrit en C :
	
	\begin{verbatim}

grammar GrammaireSimple;

options {
  language = Java;
}

tokens {
    PLUS    = '+' ;
    MINUS   = '-' ;
    MULT    = '*' ;
    DIV = '/' ;
}
 
@members {
    public static void Main(string[] args) {
        SimpleCalcLexer lex = new SimpleCalcLexer(new ANTLRFileStream(args[0]));
        CommonTokenStream tokens = new CommonTokenStream(lex);
 
        SimpleCalcParser parser = new SimpleCalcParser(tokens);
 
        try {
            parser.expr();
        } catch (RecognitionException e)  {
            Console.Error.WriteLine(e.StackTrace);
        }
    }
}
 
 % PARSER RULES
 
expr    : term ( ( PLUS | MINUS )  term )* ;
 
term    : factor ( ( MULT | DIV ) factor )* ;
 
factor  : NUMBER ;

 % LEXER RULES
 
NUMBER  : (DIGIT)+ ;
 
WHITESPACE : ( '\t' | ' ' | '\r' | '\n'| '\u000C' )+    { $channel = Hidden; } ;
 
fragment DIGIT  : '0'..'9' ;

	\end{verbatim}
\item Et maintenant le même exemple en Java :
\begin{verbatim}

grammar GrammaireSimple;

options {
  language = Java;
}
tokens {
    PLUS    = '+' ;
    MINUS   = '-' ;
    MULT    = '*' ;
    DIV = '/' ;
}
 
@members {
    public static void Main(string[] args) {
        GrammaireSimpleLexer lex = new GrammaireSimpleLexer(new ANTLRFileStream(args[0]));
        CommonTokenStream tokens = new CommonTokenStream(lex);
 
        GrammaireSimplecParser parser = new GrammaireSimpleParser(tokens);
 
        try {
            parser.expr();
        } catch (RecognitionException e)  {
            Console.Error.WriteLine(e.StackTrace);
        }
    }
}
 
 %PARSER RULES
 
expr    : term ( ( PLUS | MINUS )  term )* ;
 
term    : factor ( ( MULT | DIV ) factor )* ;
 
factor  : NUMBER ;
 
 
 %LEXER RULES
 
NUMBER  : (DIGIT)+ ;
 
WHITESPACE : ( '\t' | ' ' | '\r' | '\n'| '\u000C' )+    { $channel = Hidden; } ; 
fragment DIGIT  : '0'..'9' ;

\end{verbatim}

\end{itemize}
\subsubsubsection{Compiler}
La commande pour compiler notre exemple : 

\begin{verbatim}

java org.antlr.Tool GrammaireSimple.g

\end{verbatim}

ANTLR génère les fichiers sources pour le lexer et le parser ( GrammaireSimpleLexer.java et GrammaireSimpleParser.java ) copiez ces deux fichiers dans le bonne endroit dans notre IDE, ensuite vous pouvez compilez.

\subsubsection{Définir notre propre grammaire}
Dans la section précédente nous, avons vu comment installer et compiler avec ANTLR, dans cette partie nous allons vous montrez comment on a créer notre propre grammaire pour calculatrice simple.
\subsubsubsection{La grammaire}
Commençons par définir une expression arithmétique simple :

\begin{verbatim}

grammar GrammaireSimple;
 
add : NUMBER PLUS NUMBER;
 
NUMBER  : ('0'..'9')+ ;
 
PLUS    : '+';

\end{verbatim}
Cette exemple contient deux règles lexicales \textsl{NUMBER} et \textsl{PLUS} puis une règles syntaxiques \textsl{add}
\begin{itemize}

\item \textsl{PLUS} Unité lexicale qui contient une seule caractère : +
\item \textsl{NUMBER} Unité lexicale qui contient n'importe quel caractère compris entre 0 et 9
\item \textsl{add} Règle syntaxique qui attend exactement et dans cette ordre \textsl{NUMBER} \textsl{+} \textsl{NUMBER}, toute autre expression affichere une erreur.
\end{itemize}

\subsubsubsection{Addition répétée}
Pour écrire une expression avec plusieurs addition : 

\begin{verbatim}
add: NUMBER (PLUS NUMBER)*
\end{verbatim}

\textsl{*} : signifie plusieurs fois

\subsubsubsection{Addition et soustraction}

\begin{verbatim}

add: NUMBER ((PLUS | MINUS) NUMBER)*
 
MINUS : '-';

\end{verbatim}

|: signifie \textsl{ou}

\subsubsubsection{Expression récursive}
Pour analyser compètement  une expression arithmétique :

\begin{verbatim}
expr    : term ( ( PLUS | MINUS )  term )* ;
term    : factor ( ( MULT | DIV ) factor )* ;
factor  : NUMBER ;
 
MULT : '*';
DIV  : '/';
\end{verbatim} 

\subsubsubsection{Les espaces blancs}
Notre grammaire ne tolère pas les espaces blancs, elle retournera une erreur dans les cas suivant : 
\begin{itemize}

\item Espaces
\item Tabulations
\item Retoure à la ligne 
\item etc...

\end{itemize}

Pour cela nous devons définir ces espaces blancs,et dire au LEXER tolèrer ces espaces blancs :

\begin{itemize}

\item Une espace : ' '
\item Une tabulation : '\\t'
\item Un Retour à la ligne : '\\n'
\item etc...

\end{itemize}
 Mettons ça enssemble et séparons les par un \textsl{ou} : 

\begin{verbatim}

WHITESPACE : ( '\t' | ' ' | '\r' | '\n'| '\u000C' )+;

\end{verbatim}

Malgré ce que nous venons de faire, notre grmmaire retrourneras toujours une erreur dans le cas suivant par exemple :
\begin{verbatim}

3 + 4*5

\end{verbatim}
En effet, ANTLR sauvegarde deux chaines de communications entre le LEXER et le PARSER, une chaine cachée et une chaine par défaut.Généralement le PARSER fait appel à la chaine par défaut, nous pouvons ainsi récupérer cette chaine et la cachée :

\begin{verbatim}

WHITESPACE : ( '\t' | ' ' | '\r' | '\n'| '\u000C' )+ { $channel = HIDDEN; };

\end{verbatim}

\subsubsubsection{Résultat final}

Nous pouvons utiliser quelques techniques pour rendre le code plus lisible :

\begin{itemize}

\item Commentaire sur une ligne : //
\item Commentaire sur plusieurs lignes: /*......*/
\item Réunir toutes les unités lexicales dans section \textsl{tokens} au début du fichier
\end{itemize}

\begin{verbatim}

grammar GrammaireSimple;
 
tokens {
    PLUS    = '+' ;
    MINUS   = '-' ;
    MULT    = '*' ;
    DIV = '/' ;
}
 
/*------------------------------------------------------------------
 * PARSER RULES
 *------------------------------------------------------------------*/
 
expr    : term ( ( PLUS | MINUS )  term )* ;
 
term    : factor ( ( MULT | DIV ) factor )* ;
 
factor  : NUMBER ;
 
/*------------------------------------------------------------------
 * LEXER RULES
 *------------------------------------------------------------------*/
 
NUMBER  : (DIGIT)+ ;
 
WHITESPACE : ( '\t' | ' ' | '\r' | '\n'| '\u000C' )+    { $channel = HIDDEN; } ;
 
fragment DIGIT  : '0'..'9' ;

\end{verbatim}

\subsubsubsection{Point d'entrer pour Java}

\begin{verbatim}

@members {
    public static void Main(string[] args) {
        GrammaireSimpleLexer lex = new GrammaireSimpleLexer(new ANTLRFileStream(args[0]));
        CommonTokenStream tokens = new CommonTokenStream(lex);
 
        GrammaireSimplecParser parser = new GrammaireSimpleParser(tokens);
 
        try {
            parser.expr();
        } catch (RecognitionException e)  {
            Console.Error.WriteLine(e.StackTrace);
        }
    }
}
\end{verbatim}

\subsubsubsection{Générer du code dans un autre langage}
Si vous n'aimez pas Java vous pouvez utilisez :  

\begin{itemize}
\item Ada
\item C 
\item C++
\item C \#
\item Ryby
\item Perl
\item etc...
\end{itemize}

\begin{verbatim}

grammar GrammaireSimple;
 
options {
    language=CSharp2;
}

\end{verbatim}

\subsection{Comparaison entre YACC et ANTLR}

La différence majeure entre Yacc et Antler est que Yacc est une analyseur syntaxique de type LALR, alors que Antlr est de type LL. C’est une différence pour plusieurs application, par exemple :

\begin{alltt}
expr ::= expr '+' expr
      | expr '-' expr
      | '(' expr ')'
      | NUM ;
\end{alltt}
    
Antlr ne peut en aucun cas gérer cette grammaire telle qu’elle est. Pour ce faire, Antlr comme  tout autre analyseur syntaxique a besoin d’éliminer le récursivité à gauche avant de la traiter.

D’un autre côté Yacc n’a aucun problèmes avec des grammaires de cette forme, bien qu’elle soit récursive à gauche, il peut parfaitement la traiter.
De ce fait, On peut dire que Yacc est plus facile à utiliser du principe que les grammaire LR n’ont pas de problèmes de récursivité qui peut être complexe dans certains cas, c’est la raison pour laquelle la plupart des grammaires de nos jours sont orientées LR, mais même devant toute cette facilité, on ne peut en aucun cas négliger Antlr car aucun autre outils ne l’atteint encore en termes de performance et de flexibilité.

\section{Xtext}
\subsection{Definition}
Xtext est un framework pour le développement de langages de programmation et de DSL (Domain Specific programming language).
Le framework Xtext s’appuie sur une grammaire générée ANTLR ainsi que le framework de modélisation EMF.

Il fonctionne sur une JVM (Machine Virtuelle Java) et est constitué de plusieurs API qui vous permettent de décrire les différents aspects du langage que vous voulez créer et propose une implémentation complète de ce langage. Notons que le langage développé sera alors un langage qui s'appuie et qui surcouche le langage Java. C'est-à-dire que les objets offerts par ce framework sont complètement des objets Java et le développement du compilateur de votre langage sera alors écrit en Java.

Xtext peut servir entre autres à proposer des solutions dans les domaines tels que : les systèmes embarqués, l'automobile, les appareils mobiles, l'automatique, les jeux vidéo, etc.

Notons aussi que les langages développés via Xtext peuvent selon son tutoriel être définis non seulement avec le langage Java, mais aussi d'autres langages tels que C, C++, C\# objective C, Python et Ruby. De plus, une fois que le DSL est mis en œuvre , son utilisation devient indépendante de la JVM. 

Xtext couvre tous les aspects d’un IDE moderne : parseur, compilateur, interpréteur et intégration complète dans l’environnement de développement Eclipse.

Xtext fournit un environnement convivial aux utilisateurs d’un DSL.

\subsection{Definition DSL}
DSL:est un langage de programmation dont les spécifications sont à un domaine d’applications précis, la construction des langages dédiés diffère fondamentalement de celle d’un langage classique, le processus de développement  peut s'avérer très complexe, sa conception nécessite une double compétence sur le domaine à traiter et en développement informatique (exp: SQL destiné à interroger ou manipuler une base de données relationnelle)

\subsection{Definition Eclipse}
Eclipse IDE est un environnement de développement intégré libre (le terme Eclipse désigne également le projet correspondant, lancé par IBM) extensible, universel et polyvalent, permettant potentiellement de créer des projets de développement mettant en œuvre n'importe quel langage de programmation. Eclipse IDE est principalement écrit en Java (à l'aide de la bibliothèque graphique SWT, d'IBM), et ce langage, grâce à des bibliothèques spécifiques, est également utilisé pour écrire des extensions.

La spécificité d'Eclipse IDE vient du fait de son architecture totalement développée autour de la notion de plug-in.


\subsection{Fonctionnalités Xtext}

Parmi les fonctionnalités qu’offre Xtext:
\begin{itemize}
			\item -coloration syntaxique: Suivant les éléments de la grammaire , Xtext propose une coloration syntaxique entièrement     personnalisable.
			\item -auto complétion: auto complétion sur les éléments du langage 
			\item -validation: Xtext valide le contenu de l'éditeur à la volée, produisant ainsi un retour direct à l’utilisateur en cas d’erreur de syntaxe.
			\item -intégration avec d’autres composants Eclipse 
\end{itemize}

\subsection{Diagramme de flux}

\begin{figure}[h]
	\centering
		\includegraphics[width=1.10\textwidth]{DiagrammeFluxXtext.png}
	\caption{Diagramme de flux Xtext}
	\label{fig:DiagrammeFluxXtext}
\end{figure}\FloatBarrier

\subsubsection{Exemple}
On va prendre l'exemple de la grammaire précédente, et on va voir comment générer un éditeur sous forme d'un plugin eclipse avec Xtext.
\subsubsection{Etape 1: Création d'un projet Xtext}


\begin{figure}[h]
	\centering
		\includegraphics[width=1.10\textwidth,height=10cm]{1.PNG}
		\caption{Création d'un projet Xtext}
	\label{fig:1}
\end{figure}\FloatBarrier



Tout d'abord on va créer un projet Xtext avec comme nom du projet org.xtext.demo,langage du projet org.xtext.example.demo et comme extension .demo.
A la fin de la création, on remarque que 3 projets ont été crées, le premier correspond plus à la partie runtime dans laquelle on a notre grammaire et certains éléments qui sont pour l'instant vierge, un deuxième qui concerne plus la partie interface utilisateur(tout ce qui est propre à l'éditeur) et puis le troisième qui est un projet test.

\subsubsection{Etape 2: Definition du langage}

\begin{figure}[h]
	\centering
		\includegraphics[width=1.10\textwidth]{2.PNG}
		\caption{Definition du langage}
	\label{fig:2}
\end{figure}\FloatBarrier


Ici on va définir notre langage  avec une grammaire proche de celle de Antlr.

Pour le faire, on va dans le fichier demo.xtext et on écrit la grammaire suivante:

\begin{verbatim}

grammar org.xtext.example.Demo with org.eclipse.xtext.common.Terminals

generate demo "http://www.xtext.org/example/Demo"

Model:
	categories+=Categorie+
	rule=Rule;
	
Categorie:
	'category' name=ID;
	
Rule:
	first=RuleExpression
	("else" next=(Rule | RatioExpression))?;

RuleExpression:
	"if" test=TestExpression "then" ratio=RatioExpression;


TestExpression:
	"category" "is" categorie=[Categorie];

RatioExpression:
	"ratio" "is" ratio=INT;

\end{verbatim}

 \subsubsection{Etape 3: Generation des artifacts}

\begin{figure}[h]
	\centering
		\includegraphics[width=1.10\textwidth]{3.png}
		\caption{Generation des artifacts}
	\label{fig:3}
\end{figure}\FloatBarrier

Pour faire la génération, on fait un click droit sur le fichier .xtext,run as >Generate Xtext Artifacts.

Apres la génération, les projets se sont remplis, et j'ai certain services qui sont proposés :formatteur, generateur, validateur...


 \subsubsection{Etape 4: Faire un test}

\begin{figure}[h]
	\centering
		\includegraphics[width=1.10\textwidth]{4.png}
		\caption{Faire un test}
	\label{fig:4}
\end{figure}\FloatBarrier


Pour faire un test, il suffit de faire un clic droit sur le projet run as >Eclipse Application, un Eclipse va etre lancé qui a maintenant le plugin.

On crée tout d'abord un projet, et dans ce projet on va créer un fichier .demo.

En utilisant le content assist(ctrl+espace) pour la première fois, le mot category est généré, vu qu'il connait la grammaire et il sait que par default ça commence par une catégorie, après on aura le choix ou bien d'écrire une autre catégorie ou commencer une expression.


\subsubsection{Etape 5: Ajouter une validation}

\begin{figure}[h]
	\centering
		\includegraphics[width=1.10\textwidth]{5.PNG}
		\caption{Ajouter une validation}
	\label{fig:5}
\end{figure}\FloatBarrier


Ajouter une validation, veut dire pour nous poser une régle sur la grammaire (exp:un nom de categorie commence toujours par une majuscule), si l'utilisateur entre un nom en minuscule, on va le souligner.

Pour faire ceci, on va créer dans le package org.xtext.example.validation géneré par Eclipse une classe qu'on va appeler DemoValidator et qui va contenir la méthode checkCategory qui fait un test sur la première lettre du nom de la categorie et qui surligne le nom si cette lettre est en minuscule.

\begin{verbatim}
   /*
 * generated by Xtext
 */
package org.xtext.example.validation;
import org.eclipse.xtext.validation.Check;
import org.xtext.example.demo.Category;
import org.xtext.example.demo.DemoPackage;

/**
 * Custom validation rules. 
 *
 * see http://www.eclipse.org/Xtext/documentation.html#validation
 */
class DemoValidator extends AbstractDemoValidator {

@Check
	public void checkGreetingStartsWithCapital(Category cat) {
	if (!Character.isUpperCase(cat.getName().charAt(0))) {
			error("le nom doit commencer par une majuscule", cat,
							DemoPackage.eINSTANCE.getCategory_Name(), "CapitalName");
		}
	}
}
\end{verbatim}

\newpage
\section{Conclusion}
\label{hints}

En analyse syntaxique, quelque soit la méthode ou l’approche utilisée, le résultat est le même. Il suffit juste de savoir choisir le mieux approprié selon les cas. De ce fait, on ne peut pas dire qu’un outil ou une approche est meilleure qu’une autre, cas a toute méthode ces qualités et ces défauts.

L’étape qui suit l’analyse syntaxique est l’analyse sémantique, elle est responsable des vérifications par rapport au sens des mots dans un langage:
La résolution des noms qui permet par exemple d’éviter deux variables avec le même nom.
La vérification des types en termes de compatibilité des instructions, et enfin l’affectation définitive qui nécessitant que les variables locales soit initialisé avant d’être utilisées.

\newpage
\section{Références}
\label{hints}

\bibliography{bibliographie}
\bibliographystyle{abbrv}
\end{document}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% coding: utf-8
%%% LaTeX-command: "latex -file-line-error"
%%% End:
